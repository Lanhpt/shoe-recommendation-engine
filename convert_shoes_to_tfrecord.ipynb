{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_int = {'Boots': 1, 'Sandals': 2, 'Shoes': 3, 'Slippers': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current total img_list has len: 12832\n",
      "current total label_list has len: 12832\n",
      "current total img_list has len: 18573\n",
      "current total label_list has len: 18573\n",
      "current total img_list has len: 19856\n",
      "current total label_list has len: 19856\n",
      "current total img_list has len: 50025\n",
      "current total label_list has len: 50025\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def get_all_images(path, resize):\n",
    "    img_list = []\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = path + '/' + filename\n",
    "        if os.path.isdir(file_path):\n",
    "            img_list += get_all_images(file_path, resize)\n",
    "        elif filename.lower().endswith('.jpg'):\n",
    "            with Image.open(file_path) as img:\n",
    "                #transform images before saving\n",
    "                    #grayscale\n",
    "                img = img.convert('LA')\n",
    "                    #resize\n",
    "                img = img.resize(resize)\n",
    "                img_list.append(np.array(img))\n",
    "          \n",
    "    return img_list\n",
    "    \n",
    "#convert back to img\n",
    "#arr2im = Image.fromarray(im2arr)\n",
    "from random import sample\n",
    "\n",
    "def tt_split(img_array, lbl_array, test_ratio):\n",
    "    l = img_array.shape[0] #length of data \n",
    "    f = int(l*test_ratio) #number of elements you need (test elems)\n",
    "    test_indices = sample(range(l),f)\n",
    "    train_indices = [i for i in range(l) if i not in test_indices]\n",
    "    \n",
    "    if (bool(set(test_indices) & set(train_indices))):\n",
    "        print('WARNING: incorrect split! Test and Train overlap!')\n",
    "        \n",
    "\n",
    "    test_data_img = img_array[test_indices]\n",
    "    train_data_img = img_array[train_indices]\n",
    "    test_data_lbl = lbl_array[test_indices]\n",
    "    train_data_lbl = lbl_array[train_indices]\n",
    "    \n",
    "    return train_data_img, test_data_img, train_data_lbl, test_data_lbl\n",
    "    \n",
    "    \n",
    "\n",
    "def read_shoe_data(directory, dtype=tf.uint8, test_ratio=0.2, resize=(28, 28)):\n",
    "    #resize is (width, height)\n",
    "\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        path = directory + '/' + filename\n",
    "        if os.path.isdir(path):\n",
    "            label = filename\n",
    "            label_path = path\n",
    "            #add all images in all subfolders to list\n",
    "            img_list_for_label = get_all_images(label_path, resize)\n",
    "            img_list += img_list_for_label\n",
    "            label_list += ([label_to_int[label]] * len(img_list_for_label))\n",
    "            \n",
    "            print('current total img_list has len:', len(img_list))\n",
    "            print('current total label_list has len:', len(label_list))\n",
    "    img_array = np.array(img_list)\n",
    "    label_array = np.array(label_list)\n",
    "            \n",
    "    return tt_split(img_array, label_array, test_ratio)\n",
    "            \n",
    "        \n",
    "train_data_img, test_data_img, train_data_lbl, test_data_lbl = read_shoe_data('data/ut-zap50k-images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_img len: (40020, 28, 28, 2)\n",
      "test_data_img len: (10005, 28, 28, 2)\n"
     ]
    }
   ],
   "source": [
    "print('train_data_img len:', train_data_img.shape)\n",
    "print('test_data_img len:', test_data_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(train_data_img[0])\n",
    "img.show()\n",
    "\n",
    "img = Image.fromarray(test_data_img[0])\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLabelHolder():\n",
    "    def __init__(self, image_array, label_array):\n",
    "        self.num_examples = len(image_array)\n",
    "        self.images = image_array\n",
    "        self.labels = label_array\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, train_img_lbls, test_img_lbls):\n",
    "        self.train = train_img_lbls\n",
    "        self.test = test_img_lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(ImageLabelHolder(train_data_img, train_data_lbl), ImageLabelHolder(test_data_img, test_data_lbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing shoetmp/data/train.tfrecords\n",
      "Writing shoetmp/data/test.tfrecords\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Converts MNIST data to TFRecords file format with Example protos.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "dirname = 'shoetmp/data'\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def convert_to(data_set, name):\n",
    "  \"\"\"Converts a dataset to tfrecords.\"\"\"\n",
    "  images = data_set.images\n",
    "  labels = data_set.labels\n",
    "  num_examples = data_set.num_examples\n",
    "\n",
    "  if images.shape[0] != num_examples:\n",
    "    raise ValueError('Images size %d does not match label size %d.' %\n",
    "                     (images.shape[0], num_examples))\n",
    "  rows = images.shape[1]\n",
    "  cols = images.shape[2]\n",
    "  depth = images.shape[3]\n",
    "\n",
    "  filename = os.path.join(FLAGS.directory, name + '.tfrecords')\n",
    "  print('Writing', filename)\n",
    "  with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "    for index in range(num_examples):\n",
    "      image_raw = images[index].tostring()\n",
    "      example = tf.train.Example(\n",
    "          features=tf.train.Features(\n",
    "              feature={\n",
    "                  'height': _int64_feature(rows),\n",
    "                  'width': _int64_feature(cols),\n",
    "                  'depth': _int64_feature(depth),\n",
    "                  'label': _int64_feature(int(labels[index])),\n",
    "                  'image_raw': _bytes_feature(image_raw)\n",
    "              }))\n",
    "      writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "def old_main(unused_argv):\n",
    "  print(type(FLAGS))\n",
    "  print(FLAGS.directory)\n",
    "  # Get the data.\n",
    "\n",
    "  #this implicitly makes the relevant directory\n",
    "  data_sets = mnist.read_data_sets(FLAGS.directory,\n",
    "                                   dtype=tf.uint8,\n",
    "                                   reshape=False,\n",
    "                                   validation_size=FLAGS.validation_size)\n",
    "    \n",
    "  print(type(data_sets.train.images))\n",
    "\n",
    "  img_train = data_sets.train.images\n",
    "    \n",
    "  print(img_train.shape)\n",
    "\n",
    "  # Convert to Examples and write the result to TFRecords.\n",
    "  convert_to(data_sets.train, 'train')\n",
    "  convert_to(data_sets.validation, 'validation')\n",
    "  convert_to(data_sets.test, 'test')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def main(unused_argv):\n",
    "  # Get the data.\n",
    "\n",
    "  #read in images from files and build a numpy array after resizing to 28x28 and gray-scaling.\n",
    "    \n",
    "  #need a training and testing examples. \n",
    "\n",
    "  #may as welll include labels\n",
    "    \n",
    "\n",
    "  data_sets = dataset\n",
    "\n",
    "  if not os.path.exists(dirname):\n",
    "      os.makedirs(dirname)\n",
    "\n",
    "  # Convert to Examples and write the result to TFRecords.\n",
    "  convert_to(data_sets.train, 'train')\n",
    "  #convert_to(data_sets.validation, 'validation')\n",
    "  convert_to(data_sets.test, 'test')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "      '--directory',\n",
    "      type=str,\n",
    "      default=dirname,\n",
    "      help='Directory to download data files and write the converted result'\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--validation_size',\n",
    "      type=int,\n",
    "      default=5000,\n",
    "      help=\"\"\"\\\n",
    "      Number of examples to separate from the training data for the validation\n",
    "      set.\\\n",
    "      \"\"\"\n",
    "  )\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
